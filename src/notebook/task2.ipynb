{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, Flatten, LSTM, SimpleRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# import the data\n",
    "fraud_data = pd.read_csv('../../data/fraud_data_preprocessed.csv')\n",
    "creditcard_data = pd.read_csv('../../data/creditcard.csv')\n",
    "\n",
    "# convert signup_time and purchase_time to datetime\n",
    "fraud_data['signup_time'] = pd.to_datetime(fraud_data['signup_time']).astype(np.int64)\n",
    "fraud_data['purchase_time'] = pd.to_datetime(fraud_data['purchase_time']).astype(np.int64)\n",
    "fraud_data.drop(columns=['user_id'], inplace=True)\n",
    "fraud_data.drop(columns=['device_id'], inplace=True)\n",
    "\n",
    "X_fraud = fraud_data.drop(columns=['class'])\n",
    "y_fraud = fraud_data['class']\n",
    "\n",
    "X_creditcard = creditcard_data.drop(columns=['Class'])  # Features from the credit card dataset\n",
    "y_creditcard = creditcard_data['Class']    \n",
    "\n",
    "\n",
    "X_fraud_train, X_fraud_test, y_fraud_train, y_fraud_test = train_test_split(X_fraud, y_fraud, test_size=0.3, random_state=42)\n",
    "X_creditcard_train, X_creditcard_test, y_creditcard_train, y_creditcard_test = train_test_split(X_creditcard, y_creditcard, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'MLP': MLPClassifier(max_iter=1000)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train and evaluate the models on the fraud dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model on fraud data...\n",
      "Logistic Regression model performance on fraud data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     41117\n",
      "           1       0.00      0.00      0.00      4217\n",
      "\n",
      "    accuracy                           0.91     45334\n",
      "   macro avg       0.45      0.50      0.48     45334\n",
      "weighted avg       0.82      0.91      0.86     45334\n",
      "\n",
      "\n",
      "\n",
      "Training Decision Tree model on fraud data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree model performance on fraud data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.94      0.95     41117\n",
      "           1       0.49      0.57      0.53      4217\n",
      "\n",
      "    accuracy                           0.90     45334\n",
      "   macro avg       0.72      0.75      0.74     45334\n",
      "weighted avg       0.91      0.90      0.91     45334\n",
      "\n",
      "\n",
      "\n",
      "Training Random Forest model on fraud data...\n",
      "Random Forest model performance on fraud data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     41117\n",
      "           1       1.00      0.54      0.70      4217\n",
      "\n",
      "    accuracy                           0.96     45334\n",
      "   macro avg       0.98      0.77      0.84     45334\n",
      "weighted avg       0.96      0.96      0.95     45334\n",
      "\n",
      "\n",
      "\n",
      "Training Gradient Boosting model on fraud data...\n",
      "Gradient Boosting model performance on fraud data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98     41117\n",
      "           1       1.00      0.54      0.70      4217\n",
      "\n",
      "    accuracy                           0.96     45334\n",
      "   macro avg       0.98      0.77      0.84     45334\n",
      "weighted avg       0.96      0.96      0.95     45334\n",
      "\n",
      "\n",
      "\n",
      "Training MLP model on fraud data...\n",
      "MLP model performance on fraud data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      1.00      0.95     41117\n",
      "           1       0.00      0.00      0.00      4217\n",
      "\n",
      "    accuracy                           0.91     45334\n",
      "   macro avg       0.45      0.50      0.48     45334\n",
      "weighted avg       0.82      0.91      0.86     45334\n",
      "\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "# Train models on fraud_data\n",
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model on fraud data...\")\n",
    "    model.fit(X_fraud_train, y_fraud_train)\n",
    "    y_pred_fraud = model.predict(X_fraud_test)\n",
    "    print(f\"{name} model performance on fraud data:\")\n",
    "    print(classification_report(y_fraud_test, y_pred_fraud))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models on creditcard_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression model on credit card data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression model performance on credit card data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.80      0.62      0.70       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.90      0.81      0.85     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "\n",
      "Training Decision Tree model on credit card data...\n",
      "Decision Tree model performance on credit card data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.72      0.82      0.76       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.86      0.91      0.88     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "\n",
      "Training Random Forest model on credit card data...\n",
      "Random Forest model performance on credit card data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.93      0.82      0.87       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.97      0.91      0.94     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "\n",
      "Training Gradient Boosting model on credit card data...\n",
      "Gradient Boosting model performance on credit card data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.89      0.12      0.22       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.95      0.56      0.61     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "\n",
      "Training MLP model on credit card data...\n",
      "MLP model performance on credit card data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     85307\n",
      "           1       0.55      0.12      0.20       136\n",
      "\n",
      "    accuracy                           1.00     85443\n",
      "   macro avg       0.77      0.56      0.60     85443\n",
      "weighted avg       1.00      1.00      1.00     85443\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f\"Training {name} model on credit card data...\")\n",
    "    model.fit(X_creditcard_train, y_creditcard_train)\n",
    "    y_pred_creditcard = model.predict(X_creditcard_test)\n",
    "    print(f\"{name} model performance on credit card data:\")\n",
    "    print(classification_report(y_creditcard_test, y_pred_creditcard))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 628us/step - accuracy: 0.8258 - loss: 1728086802432000.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 656us/step - accuracy: 0.8278 - loss: 223273589669888.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step - accuracy: 0.8296 - loss: 68500903165952.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630us/step - accuracy: 0.8312 - loss: 15457033650176.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 631us/step - accuracy: 0.9169 - loss: 6.1407\n",
      "Epoch 6/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 615us/step - accuracy: 0.9186 - loss: 0.3119\n",
      "Epoch 7/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 630us/step - accuracy: 0.9236 - loss: 0.2680\n",
      "Epoch 8/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 624us/step - accuracy: 0.9269 - loss: 0.2546\n",
      "Epoch 9/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 639us/step - accuracy: 0.9271 - loss: 0.2552\n",
      "Epoch 10/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 629us/step - accuracy: 0.9305 - loss: 0.2531\n",
      "\u001b[1m1417/1417\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 330us/step\n",
      "CNN model performance on fraud data:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     41117\n",
      "           1       0.91      0.39      0.55      4217\n",
      "\n",
      "    accuracy                           0.94     45334\n",
      "   macro avg       0.92      0.69      0.76     45334\n",
      "weighted avg       0.94      0.94      0.93     45334\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_fraud_train_reshaped = X_fraud_train.values.reshape(X_fraud_train.shape[0], X_fraud_train.shape[1], 1)\n",
    "X_fraud_test_reshaped = X_fraud_test.values.reshape(X_fraud_test.shape[0], X_fraud_test.shape[1], 1)\n",
    "\n",
    "cnn_model = Sequential([\n",
    "    Conv1D(64, kernel_size=3, activation='relu', input_shape=(X_fraud_train.shape[1], 1)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "cnn_model.fit(X_fraud_train_reshaped, y_fraud_train, epochs=10, batch_size=32)\n",
    "\n",
    "\n",
    "y_pred_cnn = (cnn_model.predict(X_fraud_test_reshaped) > 0.5).astype(\"int32\")\n",
    "print(\"CNN model performance on fraud data:\")\n",
    "print(classification_report(y_fraud_test, y_pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/junior/Documents/Tenx/fraud_detection/.venv/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8286 - loss: 35807763103744.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8250 - loss: 124570443776.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8289 - loss: 17032890368.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8299 - loss: 15013863424.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8341 - loss: 286278112.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8367 - loss: 33398008.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8334 - loss: 1758659072.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8283 - loss: 307417568.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8336 - loss: 8670291.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8277 - loss: 12627553.0000\n",
      "Epoch 1/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8023 - loss: 342429857218560.0000\n",
      "Epoch 2/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8699 - loss: 2563714580480.0000\n",
      "Epoch 3/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8337 - loss: 231555317760.0000\n",
      "Epoch 4/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8363 - loss: 9390459453440.0000\n",
      "Epoch 5/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8332 - loss: 1516729663488.0000\n",
      "Epoch 6/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8535 - loss: 26665717760.0000\n",
      "Epoch 7/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8284 - loss: 34504696.0000\n",
      "Epoch 8/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2ms/step - accuracy: 0.8298 - loss: 462678136979456.0000\n",
      "Epoch 9/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8306 - loss: 77299034619904.0000\n",
      "Epoch 10/10\n",
      "\u001b[1m3306/3306\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2ms/step - accuracy: 0.8314 - loss: 27609782026240.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x162c5df10>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RNN and LSTM\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    SimpleRNN(64, input_shape=(X_fraud_train.shape[1], 1), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.fit(X_fraud_train_reshaped, y_fraud_train, epochs=10, batch_size=32)\n",
    "\n",
    "# LSTM Model\n",
    "lstm_model = Sequential([\n",
    "    LSTM(64, input_shape=(X_fraud_train.shape[1], 1), activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "lstm_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "lstm_model.fit(X_fraud_train_reshaped, y_fraud_train, epochs=10, batch_size=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment setting failed: Cannot set a deleted experiment 'fraud_detection' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/10/27 12:05:35 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/10/27 12:05:36 INFO mlflow.tracking._tracking_service.client: ğŸƒ View run welcoming-bee-741 at: http://127.0.0.1:5000/#/experiments/0/runs/470c39b3a77b49bb891719e5ad967ed5.\n",
      "2024/10/27 12:05:36 INFO mlflow.tracking._tracking_service.client: ğŸ§ª View experiment at: http://127.0.0.1:5000/#/experiments/0.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Set tracking URI to point to the local MLflow server\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "\n",
    "\n",
    "\n",
    "# Try using experiment_id instead of experiment name\n",
    "try:\n",
    "    mlflow.set_experiment(experiment_id=\"1\")  # Replace with your actual experiment ID\n",
    "except Exception as e:\n",
    "    print(f\"Experiment setting failed: {e}\")\n",
    "\n",
    "# Start MLflow run\n",
    "with mlflow.start_run():\n",
    "    # Train the model\n",
    "    model = RandomForestClassifier(n_estimators=100, max_depth=None)\n",
    "    model.fit(X_fraud_train, y_fraud_train)\n",
    "\n",
    "    # Log the trained model\n",
    "    mlflow.sklearn.log_model(model, \"random_forest_model\")\n",
    "\n",
    "    # Make predictions and calculate accuracy\n",
    "    y_pred_fraud = model.predict(X_fraud_test)\n",
    "    accuracy = accuracy_score(y_fraud_test, y_pred_fraud)\n",
    "    \n",
    "    # Log metrics and parameters\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "    mlflow.log_param(\"n_estimators\", 100)\n",
    "    mlflow.log_param(\"max_depth\", None)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
